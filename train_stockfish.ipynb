{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "train.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEln7vYTGLyu",
        "outputId": "7363d248-50ed-47e8-fff8-7323b208320f"
      },
      "source": [
        "# ensure packages are installed, uninstall normal tensorflow and ensure gpu can be used\n",
        "!pip install -qU chess"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |██▎                             | 10kB 22.8MB/s eta 0:00:01\r\u001b[K     |████▋                           | 20kB 29.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 30kB 21.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 40kB 25.4MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 51kB 20.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 61kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 71kB 15.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 81kB 16.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 92kB 15.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 102kB 16.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 112kB 16.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 122kB 16.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 133kB 16.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 143kB 16.2MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oez7luTYbdCc",
        "outputId": "b34ae4f8-9375-49fc-e66d-d10e8e535cd5"
      },
      "source": [
        "import getpass  # For hiding token input\n",
        "\n",
        "# input forms for GitHub username, email address and token\n",
        "GIT_USERNAME = input(\"\\nEnter GitHub user name: \").strip()\n",
        "GIT_EMAIL = input(\"\\nEnter GitHub email address: \").strip()\n",
        "GIT_TOKEN = getpass.getpass(\"\\nEnter GitHub token: \").strip()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Enter GitHub user name: larsaars\n",
            "\n",
            "Enter GitHub email address: lars.lars.specht@gmail.com\n",
            "\n",
            "Enter GitHub token: ··········\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lKGmlxzbdCd",
        "outputId": "197ae3ba-2f16-462c-cd06-9ccbd106e477"
      },
      "source": [
        "import os\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "# Clean sample_data\n",
        "sd = 'sample_data'\n",
        "if os.path.exists(sd):\n",
        "  print(f\"removing {sd}!\")\n",
        "  !rm -rf {sd}\n",
        "\n",
        "# GitHub repository name\n",
        "GIT_REPOSITORY = 'chess_heuristics_deep_learning'\n",
        "\n",
        "# Path to GitHub repository\n",
        "GIT_PATH = 'https://' + GIT_TOKEN + '@github.com/' + GIT_USERNAME + '/' + GIT_REPOSITORY + '.git'\n",
        "\n",
        "# Clone or pull git repository\n",
        "if not os.path.exists(GIT_REPOSITORY):\n",
        "  # Clone the github repository\n",
        "  !git clone {GIT_PATH}\n",
        "else:\n",
        "  # else pull the github repository\n",
        "  %cd /content/{GIT_REPOSITORY}\n",
        "  !git pull {GIT_PATH}\n",
        "\n",
        "%cd /content/{GIT_REPOSITORY}\n",
        "print(\"\\nDone.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "removing sample_data!\n",
            "Cloning into 'chess_heuristics_deep_learning'...\n",
            "remote: Enumerating objects: 154, done.\u001b[K\n",
            "remote: Counting objects: 100% (154/154), done.\u001b[K\n",
            "remote: Compressing objects: 100% (108/108), done.\u001b[K\n",
            "remote: Total 154 (delta 77), reused 105 (delta 40), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (154/154), 13.55 MiB | 18.62 MiB/s, done.\n",
            "Resolving deltas: 100% (77/77), done.\n",
            "/content/chess_heuristics_deep_learning\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": true
        },
        "id": "k0_pC69SGLyv"
      },
      "source": [
        "# upload the dataset to colab, the path is defined here\n",
        "dataset_path = 'data/games_stockfish.csv'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": true
        },
        "id": "uhsQUSZMGLyy"
      },
      "source": [
        "# make imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import chess\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import BatchNormalization, Dense, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeukAZX9GLyz",
        "outputId": "dce9b46d-a0c0-4786-a546-870cc9c84eef"
      },
      "source": [
        "# ensure tensorflow is imported properly\n",
        "print(tf.__version__)\n",
        "tf.config.list_physical_devices('GPU')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": true
        },
        "id": "lQWwVDnyGLyz"
      },
      "source": [
        "# utility functions for chess\n",
        "chess_dict = {\n",
        "    'p': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "    'P': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
        "    'n': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "    'N': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
        "    'b': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "    'B': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
        "    'r': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "    'R': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
        "    'q': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
        "    'Q': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
        "    'k': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
        "    'K': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
        "    '.': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "}\n",
        "\n",
        "\n",
        "def make_matrix(board):\n",
        "    pgn = board.epd()\n",
        "    foo = []\n",
        "    pieces = pgn.split(\" \", 1)[0]\n",
        "    rows = pieces.split(\"/\")\n",
        "    for row in rows:\n",
        "        foo2 = []\n",
        "        for thing in row:\n",
        "            if thing.isdigit():\n",
        "                for i in range(0, int(thing)):\n",
        "                    foo2.append('.')\n",
        "            else:\n",
        "                foo2.append(thing)\n",
        "        foo.append(foo2)\n",
        "    return foo\n",
        "\n",
        "\n",
        "def translate(matrix):\n",
        "    rows = []\n",
        "    for row in matrix:\n",
        "        terms = []\n",
        "        for term in row:\n",
        "            terms.append(chess_dict[term])\n",
        "        rows.append(terms)\n",
        "    return rows"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": true
        },
        "id": "Pm24i0cjGLyz"
      },
      "source": [
        "# create the model and compile\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=64, kernel_size=1, activation='relu', input_shape=(8, 8, 12)))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(filters=24, kernel_size=1, activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(filters=10, kernel_size=1, activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(1, activation='tanh'))\n",
        "\n",
        "model.compile(optimizer='Nadam', loss='mse')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": true
        },
        "id": "c40oSurDGLy0"
      },
      "source": [
        "# read the pandas dataframe and create X and y\n",
        "df = pd.read_csv(dataset_path, sep=';')\n",
        "X = []\n",
        "y = []"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": true
        },
        "id": "yHfRLd2wGLy1"
      },
      "source": [
        "# create dataset\n",
        "for fen, eval in zip(df.FEN, df.Evaluation): \n",
        "    # read fen with chess lib, translate to rows matrix\n",
        "    matrix = make_matrix(chess.Board(fen=fen))\n",
        "    rows = translate(matrix)\n",
        "    \n",
        "    # then add as X and y\n",
        "    X.append(rows)\n",
        "    y.append(float(eval))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": true
        },
        "id": "Z52YZ29SGLy2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea56f626-218a-4ca7-b755-ddf484115072"
      },
      "source": [
        "# redefine X and y as numpy arrays (and reshape X)\n",
        "X = np.array(X).reshape((len(X), 8, 8, 12))\n",
        "y = np.array(y)\n",
        "\n",
        "# del df to save ram\n",
        "del df\n",
        "\n",
        "y.size"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1048575"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "UxIx0nW3GLy2",
        "outputId": "311b5fa7-a69b-4210-bb92-929d7c6ccfa4"
      },
      "source": [
        "# start training\n",
        "# model file name\n",
        "h5 = 'model_stockfish.h5'\n",
        "json = 'model_stockfish.json'\n",
        "\n",
        "# save the compiled model\n",
        "with open(json, 'w') as f:\n",
        "    f.write(model.to_json())\n",
        "\n",
        "print('model written to json file')\n",
        "\n",
        "# create callbacks\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(h5,\n",
        "                                             monitor='loss',\n",
        "                                             verbose=0,\n",
        "                                             save_best_only=True,\n",
        "                                             save_weights_only=True,\n",
        "                                             mode='auto',\n",
        "                                             save_freq=1)\n",
        "es = keras.callbacks.EarlyStopping(monitor='loss', mode='min', verbose=1, patience=500)\n",
        "\n",
        "# load old model if exists\n",
        "if os.path.exists(h5):\n",
        "  model.load_weights(h5)\n",
        "  print('Imported old model; now continue with training.')\n",
        "\n",
        "# not a 1000 epochs since we want the repository to be automatically pushed back once done with the epochs\n",
        "model.fit(X, y, epochs=150, verbose=2, callbacks=[checkpoint, es])\n",
        "print('done')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model written to json file\n",
            "Epoch 1/150\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "UnimplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-2919ac98788e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# not a 1000 epochs since we want the repository to be automatically pushed back once done with the epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'done'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnimplementedError\u001b[0m: 2 root error(s) found.\n  (0) Unimplemented:  Cast string to float is not supported\n\t [[node mean_squared_error/Cast (defined at <ipython-input-12-2919ac98788e>:28) ]]\n  (1) Cancelled:  Function was cancelled before it was started\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_1519]\n\nFunction call stack:\ntrain_function -> train_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": true
        },
        "id": "fhXYvp1nGLy3"
      },
      "source": [
        "# push repository (updated model etc.) back to github\n",
        "%cd /content/{GIT_REPOSITORY}\n",
        "\"\"\"\n",
        "git add -A stages all changes\n",
        "git add . stages new files and modifications, without deletions\n",
        "git add -u stages modifications and deletions, without new files\n",
        "\"\"\"\n",
        "!git status\n",
        "\n",
        "!git add -A\n",
        "\n",
        "!git config --global user.email {GIT_EMAIL}\n",
        "!git config --global user.name {GIT_USERNAME}\n",
        "!git commit -m \"Automatically commit and push through Google Colab!\"\n",
        "\n",
        "!git push"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}